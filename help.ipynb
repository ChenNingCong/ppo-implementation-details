{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenningcong/Desktop/DeepLearning/deep/lib/python3.10/site-packages/gymnasium/vector/__init__.py:53: UserWarning: \u001b[33mWARN: `gymnasium.vector.make(...)` is deprecated and will be replaced by `gymnasium.make_vec(...)` in v1.0\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb Cell 1\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m env \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39mvector\u001b[39m.\u001b[39mmake(\u001b[39m\"\u001b[39m\u001b[39mLunarLander-v2\u001b[39m\u001b[39m\"\u001b[39m, num_envs\u001b[39m=\u001b[39mnum_envs)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m agent \u001b[39m=\u001b[39m Agent(envs\u001b[39m=\u001b[39menv)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m trainer \u001b[39m=\u001b[39m PPOTrainer(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     env \u001b[39m=\u001b[39;49menv,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     agent \u001b[39m=\u001b[39;49m agent,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     rollout_num \u001b[39m=\u001b[39;49m \u001b[39m100000\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     rollout_length \u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     epsilon \u001b[39m=\u001b[39;49m \u001b[39m0.2\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     value_loss_weight \u001b[39m=\u001b[39;49m \u001b[39m0.2\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     clip_norm \u001b[39m=\u001b[39;49m \u001b[39m0.5\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     norm_adv \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     ppo_epoch \u001b[39m=\u001b[39;49m \u001b[39m4\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W0sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     ppo_num_minibatch \u001b[39m=\u001b[39;49m \u001b[39m4\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     gamma \u001b[39m=\u001b[39;49m \u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W0sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     use_gae \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W0sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     lam \u001b[39m=\u001b[39;49m \u001b[39m0.95\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W0sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W0sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m():\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W0sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     trainer\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/Desktop/ppo-implementation-details/ppo_agent.py:72\u001b[0m, in \u001b[0;36mPPOTrainer.__init__\u001b[0;34m(self, env, agent, rollout_num, rollout_length, epsilon, value_loss_weight, clip_norm, norm_adv, ppo_epoch, ppo_num_minibatch, gamma, use_gae, lam)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv \u001b[39m=\u001b[39m env\n\u001b[1;32m     71\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 72\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m     73\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma \u001b[39m=\u001b[39m gamma\n\u001b[1;32m     74\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_env \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mnum_envs\n",
      "File \u001b[0;32m~/Desktop/DeepLearning/deep/lib/python3.10/site-packages/torch/nn/modules/module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1171\u001b[0m             \u001b[39mraise\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/Desktop/DeepLearning/deep/lib/python3.10/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    781\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/DeepLearning/deep/lib/python3.10/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    781\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/DeepLearning/deep/lib/python3.10/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    781\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/DeepLearning/deep/lib/python3.10/site-packages/torch/nn/modules/module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 804\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    805\u001b[0m p_should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    807\u001b[0m \u001b[39m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/DeepLearning/deep/lib/python3.10/site-packages/torch/nn/modules/module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1153\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(\n\u001b[1;32m   1154\u001b[0m             device,\n\u001b[1;32m   1155\u001b[0m             dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1156\u001b[0m             non_blocking,\n\u001b[1;32m   1157\u001b[0m             memory_format\u001b[39m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1158\u001b[0m         )\n\u001b[0;32m-> 1159\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(\n\u001b[1;32m   1160\u001b[0m         device,\n\u001b[1;32m   1161\u001b[0m         dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1162\u001b[0m         non_blocking,\n\u001b[1;32m   1163\u001b[0m     )\n\u001b[1;32m   1164\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1165\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mstr\u001b[39m(e) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCannot copy out of meta tensor; no data!\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/DeepLearning/deep/lib/python3.10/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron:\n\u001b[1;32m    292\u001b[0m     os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mLAZY\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 293\u001b[0m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_init()\n\u001b[1;32m    294\u001b[0m \u001b[39m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[39m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[39m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    297\u001b[0m _tls\u001b[39m.\u001b[39mis_initializing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "from ppo_agent import *\n",
    "num_envs = 4\n",
    "env = gym.vector.make(\"LunarLander-v2\", num_envs=num_envs)\n",
    "agent = Agent(envs=env)\n",
    "\n",
    "trainer = PPOTrainer(\n",
    "    env =env,\n",
    "    agent = agent,\n",
    "    rollout_num = 100000,\n",
    "    rollout_length = 128,\n",
    "    epsilon = 0.2,\n",
    "    value_loss_weight = 0.2,\n",
    "    clip_norm = 0.5,\n",
    "    norm_adv = True,\n",
    "    ppo_epoch = 4,\n",
    "    ppo_num_minibatch = 4,\n",
    "    gamma = 1.0,\n",
    "    use_gae = True,\n",
    "    lam = 0.95\n",
    ")\n",
    "def wrapper():\n",
    "    trainer.train()\n",
    "wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482.4233254782967"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def find_n(x,r,a):\n",
    "    return math.log(1 - x*(1-r)/a)/math.log(r)\n",
    "find_n(x=99.2160, r=0.99, a=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -35.69843292236328\n",
      "10 100.80744934082031\n",
      "20 24.36988067626953\n",
      "30 -47.359519958496094\n",
      "40 29.050148010253906\n",
      "50 34.70491409301758\n",
      "60 -54.39811706542969\n",
      "70 -22.364776611328125\n",
      "80 21.342021942138672\n",
      "90 -45.411705017089844\n",
      "100 50.841087341308594\n",
      "110 -21.726459503173828\n",
      "120 -27.086383819580078\n",
      "130 11.364738464355469\n",
      "Moviepy - Building video /home/chenningcong/Desktop/ppo-implementation-details/video/3.mp4/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /home/chenningcong/Desktop/ppo-implementation-details/video/3.mp4/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/chenningcong/Desktop/ppo-implementation-details/video/3.mp4/rl-video-episode-0.mp4\n",
      "Moviepy - Building video /home/chenningcong/Desktop/ppo-implementation-details/video/3.mp4/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /home/chenningcong/Desktop/ppo-implementation-details/video/3.mp4/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/chenningcong/Desktop/ppo-implementation-details/video/3.mp4/rl-video-episode-0.mp4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39menv \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39mvector\u001b[39m.\u001b[39mmake(\u001b[39m\"\u001b[39m\u001b[39mLunarLander-v2\u001b[39m\u001b[39m\"\u001b[39m, num_envs\u001b[39m=\u001b[39mnum_envs)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/Desktop/ppo-implementation-details/ppo_agent.py:204\u001b[0m, in \u001b[0;36mPPOTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39m#writer.add_scalar(\"return\", mean_value.item(), n_rollout)\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39mif\u001b[39;00m n_rollout \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m     mean_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalidate()\n\u001b[1;32m    205\u001b[0m     \u001b[39mprint\u001b[39m(n_rollout, mean_value\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/Desktop/DeepLearning/deep/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/ppo-implementation-details/ppo_agent.py:97\u001b[0m, in \u001b[0;36mPPOTrainer.validate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m sampling_length \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m     96\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, sampling_length):\n\u001b[0;32m---> 97\u001b[0m     action, action_log_prob, entropy, state_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent\u001b[39m.\u001b[39;49mget_action_and_value(obs, action\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     98\u001b[0m     next_obs, reward, terminated, truncated, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mstep(action\u001b[39m.\u001b[39mtolist())\n\u001b[1;32m     99\u001b[0m     \u001b[39m# # we disable truncation...\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     \u001b[39m# assert not np.any(truncated)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ppo-implementation-details/ppo_agent.py:49\u001b[0m, in \u001b[0;36mAgent.get_action_and_value\u001b[0;34m(self, x, action)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m     action \u001b[39m=\u001b[39m probs\u001b[39m.\u001b[39msample()\n\u001b[0;32m---> 49\u001b[0m \u001b[39mreturn\u001b[39;00m action, probs\u001b[39m.\u001b[39mlog_prob(action), probs\u001b[39m.\u001b[39mentropy(), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcritic(x)\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/DeepLearning/deep/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/DeepLearning/deep/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ppo-implementation-details/ppo_agent.py:32\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 32\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet(x)\n\u001b[1;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Desktop/DeepLearning/deep/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/DeepLearning/deep/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/DeepLearning/deep/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/DeepLearning/deep/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/DeepLearning/deep/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/DeepLearning/deep/lib/python3.10/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m~/Desktop/DeepLearning/deep/lib/python3.10/site-packages/torch/nn/functional.py:1295\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m   1294\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[39m{\u001b[39;00mp\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1295\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mdropout_(\u001b[39minput\u001b[39m, p, training) \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m _VF\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39m, p, training)\n",
      "File \u001b[0;32m~/Desktop/DeepLearning/deep/lib/python3.10/site-packages/torch/_VF.py:26\u001b[0m, in \u001b[0;36mVFModule.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(name)\n\u001b[1;32m     24\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvf \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_VariableFunctions\n\u001b[0;32m---> 26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, attr):\n\u001b[1;32m     27\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvf, attr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.env = gym.vector.make(\"LunarLander-v2\", num_envs=num_envs)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gym' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m envs \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39mvector\u001b[39m.\u001b[39mSyncVectorEnv(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m         [(\u001b[39mlambda\u001b[39;00m i : \u001b[39mlambda\u001b[39;00m : gym\u001b[39m.\u001b[39mwrappers\u001b[39m.\u001b[39mRecordVideo(gym\u001b[39m.\u001b[39mmake(\u001b[39m\"\u001b[39m\u001b[39mLunarLander-v2\u001b[39m\u001b[39m\"\u001b[39m, render_mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrgb_array\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvideo/\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.mp4\u001b[39m\u001b[39m\"\u001b[39m))(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_envs)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     )\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m trainer\u001b[39m.\u001b[39menv \u001b[39m=\u001b[39m envs\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39mno_grad\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/chenningcong/Desktop/ppo-implementation-details/help.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplay\u001b[39m(\u001b[39mself\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gym' is not defined"
     ]
    }
   ],
   "source": [
    "envs = gym.vector.SyncVectorEnv(\n",
    "        [(lambda i : lambda : gym.wrappers.RecordVideo(gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\"), f\"video/{i}.mp4\"))(i) for i in range(num_envs)]\n",
    "    )\n",
    "trainer.env = envs\n",
    "@torch.no_grad\n",
    "def play(self):\n",
    "    obs, _ = self.env.reset()\n",
    "    obs = torch.tensor(obs, device=self.device)\n",
    "    rewards = []\n",
    "    with torch.no_grad():\n",
    "        self.agent.eval()\n",
    "        terminateds = []\n",
    "        truncateds = []\n",
    "        sampling_length = 503\n",
    "        for _ in range(0, sampling_length):\n",
    "            action, action_log_prob, entropy, state_value = self.agent.get_action_and_value(obs, action=None)\n",
    "            next_obs, reward, terminated, truncated, _ = self.env.step(action.tolist())\n",
    "            rewards.append(torch.tensor(reward, device=self.device, dtype=torch.float32))\n",
    "            terminateds.append(torch.tensor(terminated, device=self.device))\n",
    "            truncateds.append(torch.tensor(truncated, device=self.device))\n",
    "            obs = next_obs\n",
    "            obs = torch.tensor(obs, device=self.device)\n",
    "        G_ts = [-1 for _ in range(sampling_length)]\n",
    "        G_t = torch.zeros(self.num_env, device=self.device)\n",
    "        for i in range(sampling_length -1, -1, -1):\n",
    "            # if truncated or done, we set gamma to zero\n",
    "            truncated_gamma = torch.where(terminateds[i] | truncateds[i], 0, self.gamma)\n",
    "            G_t = G_t * truncated_gamma + rewards[i]\n",
    "            G_ts[i] = G_t\n",
    "        return G_ts[0].mean()\n",
    "play(trainer)    \n",
    "envs.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/chenningcong/Desktop/ppo-implementation-details/video/3.mp4/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /home/chenningcong/Desktop/ppo-implementation-details/video/3.mp4/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/chenningcong/Desktop/ppo-implementation-details/video/3.mp4/rl-video-episode-0.mp4\n",
      "Moviepy - Building video /home/chenningcong/Desktop/ppo-implementation-details/video/3.mp4/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /home/chenningcong/Desktop/ppo-implementation-details/video/3.mp4/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/chenningcong/Desktop/ppo-implementation-details/video/3.mp4/rl-video-episode-0.mp4\n",
      "Moviepy - Building video /home/chenningcong/Desktop/ppo-implementation-details/video/3.mp4/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /home/chenningcong/Desktop/ppo-implementation-details/video/3.mp4/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/chenningcong/Desktop/ppo-implementation-details/video/3.mp4/rl-video-episode-0.mp4\n",
      "Moviepy - Building video /home/chenningcong/Desktop/ppo-implementation-details/video/3.mp4/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /home/chenningcong/Desktop/ppo-implementation-details/video/3.mp4/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/chenningcong/Desktop/ppo-implementation-details/video/3.mp4/rl-video-episode-0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
